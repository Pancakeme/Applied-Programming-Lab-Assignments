{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated Annealing\n",
    "\n",
    "Certain functions cannot be optimized through systematic deterministic approaches like gradient descent.  In particular, there are whole classes of optimization problems that are fundamentally hard to solve (so called NP-hard problems).  For these, there are no known algorithms that guarantee optimum solutions.\n",
    "\n",
    "Therefore, we need to look for other techniques, usually *stochastic* or probabilistic techniques.  One among these is Simulated Annealing.\n",
    "\n",
    "The name comes from the concept of Annealing in Metallurgy: by heating metal and then cooling it down while hammering it, you can get it to a more compact and strong state.  So the optimization technique here also brings in a concept of Temperature and uses that to guide the search for a solution.\n",
    "\n",
    "## Function and Optimization types\n",
    "\n",
    "While you can use SA on any arbitrary function, it makes sense to use it when regular techniques are not going to work.  An example of this is functions with multiple optima.  Here, we will also assume that we are interested in minimization of a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up imports\n",
    "%matplotlib ipympl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function with many minima\n",
    "def yfunc(x):\n",
    "    return x**2 + np.sin(8*x)\n",
    "\n",
    "xbase = np.linspace(-2, 2, 100)\n",
    "ybase = yfunc(xbase)\n",
    "# plt.plot(xbase, ybase)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent?\n",
    "\n",
    "We can try the known technique of gradient descent here.  It works -- but does not really find the global optimum.  It just goes to whichever is the nearest minimum, which could be quite far from the global optimum depending on your choice of starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up some large value for the best cost found so far\n",
    "bestcost = 100000\n",
    "# Generate several values within a search 'space' and check whether the new value is better\n",
    "# than the best seen so far.\n",
    "bestx = 1.1\n",
    "rangemin, rangemax = -5, 5 \n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(xbase, ybase)\n",
    "xall, yall = [], []\n",
    "lnall,  = ax.plot([], [], 'ro')\n",
    "lngood, = ax.plot([], [], 'go', markersize=10)\n",
    "\n",
    "# Learning rate \n",
    "lr = 0.01\n",
    "\n",
    "def yprimefunc(x):\n",
    "    return 2 * x + 8 * np.cos(8*x)\n",
    "\n",
    "def onestepderiv(frame):\n",
    "    global bestcost, bestx, lr\n",
    "    x = bestx - yprimefunc(bestx) * lr \n",
    "    bestx = x\n",
    "    y = yfunc(x)\n",
    "    lngood.set_data(x, y)\n",
    "    xall.append(x)\n",
    "    yall.append(y)\n",
    "    lnall.set_data(xall, yall)\n",
    "    # return lngood,\n",
    "\n",
    "ani= FuncAnimation(fig, onestepderiv, frames=range(10), interval=1000, repeat=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annealing\n",
    "\n",
    "The alternative is to use a random search approach.  However, as we already saw with simpler functions, random search can take you all over the place and take a long time to find the minimum.  Instead, it makes sense to initially search over a wide range, but as time goes on, reduce the range of values over which you are going to search.\n",
    "\n",
    "The first thing here is to introduce the concept of a *Move*.  This is a change from the present position to some neighbouring position, where we hope the solution is better than it is here.  Initially we would like to take large steps and move around to explore, but as time goes on and we are near an optimum, we want to take smaller steps.\n",
    "\n",
    "We do this by introducing a notion of *Temperature*.  Initially the temperature is high, and the step size is also high.  More importantly, even if the new cost becomes *worse* than the current cost, we are still willing to accept the move with a probability given by\n",
    "\n",
    "$$P(\\Delta E) = e^{-\\frac{\\Delta E}{kT}}$$\n",
    "\n",
    "Here $\\Delta E$ is the cost increase as a result of the new move, and $k$ is a constant (conceptually similar to Boltzmann's constant in statistical mechanics, which is where these ideas are inspired from).  $T$ is the present temperature.  Clearly, as $T$ decreases, the probability calculated above will tend towards $e^{-\\infty} = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial temperature\n",
    "T = 3.0\n",
    "decayrate = 0.95\n",
    "# Set up some large value for the best cost found so far\n",
    "bestcost = 100000\n",
    "# Generate several values within a search 'space' and check whether the new value is better\n",
    "# than the best seen so far.\n",
    "bestx = -2\n",
    "rangemin, rangemax = -2, 2 \n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(xbase, ybase)\n",
    "xall, yall = [], []\n",
    "lnall,  = ax.plot([], [], 'ro')\n",
    "lngood, = ax.plot([], [], 'go', markersize=10)\n",
    "def onestep(frame):\n",
    "    global bestcost, bestx, decayrate, T\n",
    "    # Generate a random value \\in -2, +2\n",
    "    dx = (np.random.random_sample() - 0.5) * T\n",
    "    x = bestx + dx\n",
    "    # print(f\"Old x = {x}, delta = {dx}\")\n",
    "    y = yfunc(x)\n",
    "    if y < bestcost:\n",
    "        # print(f\"Improved from {bestcost} at {bestx} to {y} at {x}\")\n",
    "        bestcost = y\n",
    "        bestx = x\n",
    "        lngood.set_data(x, y)\n",
    "    else:\n",
    "        toss = np.random.random_sample()\n",
    "        if toss < np.exp(-(y-bestcost)/T):\n",
    "            bestcost = y\n",
    "            bestx = x\n",
    "            lngood.set_data(x, y)\n",
    "        # print(f\"New cost {y} worse than best so far: {bestcost}\")\n",
    "        pass\n",
    "    T = T * decayrate\n",
    "    xall.append(x)\n",
    "    yall.append(y)\n",
    "    lnall.set_data(xall, yall)\n",
    "    # return lngood,\n",
    "\n",
    "ani= FuncAnimation(fig, onestep, frames=range(100), interval=100, repeat=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "## Part 1 - Simple\n",
    "\n",
    "Write a function that takes as input the following:\n",
    "\n",
    "- another function (note that in Python you can pass functions as arguments to other functions)\n",
    "- starting point\n",
    "- temperature \n",
    "- learning/decay rate\n",
    "\n",
    "and then proceeds to apply Simulated Annealing to minimize the function.  This is more or less the same as what has been given above, but you need to encapsulate it all into a simple function and demonstrate how it works on arbitrary functions.  \n",
    "\n",
    "## Part 2 \n",
    "\n",
    "Note that part 2 is also part of the regular assignment.  It is **not** optional, but is specified as a separate problem part to break the overall problem into portions in case you find this too hard to solve at one shot.  \n",
    "\n",
    "The traveling salesman problem gives you a set of city locations (x, y coordinates).  Your goal is to find a route from a given starting point that visits all the cities exactly once and then returns to the origin, with the minimum total distance covered (distance is measured as Euclidean distance $\\sqrt{(x_2-x_1)^2 + (y_2-y_1)^2}$).  \n",
    "\n",
    "You will be given a file where the first line is the number of cities *N*, and the next *N* lines give the cities as a list of x, y coordinates: for example\n",
    "```\n",
    "4\n",
    "0.0 1.5\n",
    "2.3 6.1\n",
    "4.2 1.3\n",
    "2.1 4.5\n",
    "```\n",
    "\n",
    "Your goal is to give a sequence of numbers, for example `[0 3 2 1]` which specifies the order in which to visit the cities.  Note that after the last city you will come back to the first one in the list.  \n",
    "\n",
    "Plot the cities with the path you have specified, and output the total length of the shortest path discovered so far.\n",
    "\n",
    "## Report\n",
    "\n",
    "You need to submit a .zip file that contains all your code (either notebook or plain Python files) and a PDF file (can be generated from the notebook) that clearly documents what you have implemented and how to run your code.  For part 1, you need to also show the output plot that shows how the search proceeded when run on the function given in the presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Python input and plot\n",
    "x_cities = np.array([0.0, 2.3, 4.2, 2.1])\n",
    "y_cities = np.array([1.5, 6.1, 1.3, 4.5])\n",
    "finalorder = [0, 3, 1, 2]\n",
    "\n",
    "# Rearrange for plotting\n",
    "xplot = x_cities[finalorder] \n",
    "yplot = y_cities[finalorder]\n",
    "xplot = np.append(xplot, xplot[0])\n",
    "yplot = np.append(yplot, yplot[0])\n",
    "plt.plot(xplot, yplot, 'o-')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "135c9c029983d30fe2c25215b219c39403965bc9bf9257a46b5d1e1e22d97d61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
